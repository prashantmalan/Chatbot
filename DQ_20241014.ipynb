{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPzkJ39bmCpyp250DmgUGWW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prashantmalan/Chatbot/blob/main/DQ_20241014.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ToVl0Tz7Ff-3"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.ensemble import IsolationForest\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "# Load the datasets\n",
        "transaction_data = pd.read_csv('https://raw.githubusercontent.com/prashantmalan/NSE/main/Pm_CFTC_2017649.csv')\n",
        "column_classification = pd.read_csv('https://raw.githubusercontent.com/prashantmalan/NSE/main/col_cat_5.csv')\n",
        "\n",
        "# Clean the data\n",
        "transaction_data = transaction_data[~transaction_data.applymap(lambda x: ';' in str(x)).any(axis=1)]\n",
        "transaction_data.reset_index(drop=True, inplace=True)\n",
        "transaction_data = transaction_data.applymap(lambda x: str(x).replace(',', '') if isinstance(x, str) else x)\n",
        "transaction_data = transaction_data.applymap(lambda x: str(x).replace('+', '') if isinstance(x, str) else x)\n",
        "transaction_data = transaction_data[~transaction_data.applymap(lambda x: ';' in str(x)).any(axis=1)]\n",
        "\n",
        "# Feature Engineering\n",
        "feature_categories = column_classification.set_index('Column')['Type'].to_dict()\n",
        "numeric_features = [col for col, cat in feature_categories.items() if cat == 'Amt']\n",
        "\n",
        "# Ensure numeric features exist in the DataFrame\n",
        "numeric_features = [col for col in numeric_features if col in transaction_data.columns]\n",
        "\n",
        "# Check for columns with all NaN values\n",
        "all_nan_columns = transaction_data[numeric_features].columns[transaction_data[numeric_features].isna().all()].tolist()\n",
        "\n",
        "# Option 2: Impute with a constant value (e.g., 0) if you prefer not to drop\n",
        "transaction_data[all_nan_columns] = 0\n",
        "\n",
        "# Impute missing values for numeric features\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "imputed_data = imputer.fit_transform(transaction_data[numeric_features])\n",
        "\n",
        "# Scale numeric features\n",
        "scaler = StandardScaler()\n",
        "numeric_data = scaler.fit_transform(imputed_data)\n",
        "\n",
        "# Initialize a DataFrame to store anomaly scores for each feature\n",
        "anomaly_scores_df = pd.DataFrame(index=transaction_data.index)\n",
        "\n",
        "# Loop through each feature and calculate anomaly scores\n",
        "for feature in numeric_features:\n",
        "    # Extract the feature data\n",
        "    feature_data = numeric_data[:, numeric_features.index(feature)].reshape(-1, 1)\n",
        "\n",
        "    # Train the Isolation Forest model\n",
        "    iso_forest = IsolationForest(contamination=0.01, random_state=42)\n",
        "    scores = iso_forest.fit_predict(feature_data)\n",
        "\n",
        "    # Store the anomaly scores in the DataFrame\n",
        "    anomaly_scores_df[feature] = scores\n",
        "\n",
        "# Add 'Product name' and 'Action type' columns to anomaly_scores_df\n",
        "anomaly_scores_df['Product name'] = transaction_data['Product name']\n",
        "anomaly_scores_df['Action type'] = transaction_data['Action type']\n",
        "\n",
        "# Determine the number of rows and columns for the subplot grid\n",
        "n_features = len(numeric_features)\n",
        "n_cols = 4\n",
        "n_rows = int(np.ceil(n_features / n_cols))\n",
        "\n",
        "# Create a grid of subplots\n",
        "fig = make_subplots(rows=n_rows, cols=n_cols, subplot_titles=numeric_features, horizontal_spacing=0.05, vertical_spacing=0.05)\n",
        "\n",
        "for i, feature in enumerate(numeric_features):\n",
        "    # Determine the row and column for the current subplot\n",
        "    row = i // n_cols + 1\n",
        "    col = i % n_cols + 1\n",
        "\n",
        "    # Create a scatter plot for normal data points\n",
        "    fig.add_trace(go.Scatter(\n",
        "        x=anomaly_scores_df.index[anomaly_scores_df[feature] == 1],\n",
        "        y=transaction_data[feature][anomaly_scores_df[feature] == 1],\n",
        "        mode='markers',\n",
        "        name='Normal',\n",
        "        customdata=anomaly_scores_df[anomaly_scores_df[feature] == 1][['Product name', 'Action type']],\n",
        "        hovertemplate='Product name: %{customdata[0]}<br>Action type: %{customdata[1]}<br>Value: %{y}<extra></extra>',\n",
        "        marker=dict(\n",
        "            size=8,  # Increase marker size\n",
        "            color='green',  # Color for normal data points\n",
        "            opacity=0.7\n",
        "        )\n",
        "    ), row=row, col=col)\n",
        "\n",
        "    # Create a scatter plot for anomalous data points\n",
        "    fig.add_trace(go.Scatter(\n",
        "        x=anomaly_scores_df.index[anomaly_scores_df[feature] == -1],\n",
        "        y=transaction_data[feature][anomaly_scores_df[feature] == -1],\n",
        "        mode='markers',\n",
        "        name='Anomalous',\n",
        "        customdata=anomaly_scores_df[anomaly_scores_df[feature] == -1][['Product name', 'Action type']],\n",
        "        hovertemplate='Product name: %{customdata[0]}<br>Action type: %{customdata[1]}<br>Value: %{y}<extra></extra>',\n",
        "        marker=dict(\n",
        "            size=8,  # Increase marker size\n",
        "            color='red',  # Color for anomalous data points\n",
        "            opacity=0.7\n",
        "        )\n",
        "    ), row=row, col=col)\n",
        "\n",
        "# Update layout\n",
        "fig.update_layout(\n",
        "    title='Anomaly Scores for Each Feature',\n",
        "    showlegend=False,\n",
        "    hovermode='closest',\n",
        "    font=dict(\n",
        "        size=10  # Adjust font size if needed\n",
        "    ),\n",
        "    autosize=False,\n",
        "    width=1500,  # Increase width to allow more space for plots\n",
        "    height=1200  # Increase height to fit more plots\n",
        ")\n",
        "\n",
        "# Set individual axis titles\n",
        "for i, feature in enumerate(numeric_features):\n",
        "    row = i // n_cols + 1\n",
        "    col = i % n_cols + 1\n",
        "    #fig.update_yaxes(title_text=f'{feature}', row=row, col=col, tickangle=-45)  # Tilt y-axis labels\n",
        "   # fig.update_xaxes(title_text='Index', row=row, col=col)\n",
        "\n",
        "# Show the plot\n",
        "fig.show()"
      ]
    }
  ]
}